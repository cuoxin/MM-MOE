import torch
import torch.nn as nn
import torch.nn.functional as F

# ç¡®ä¿è¿™ä¸‰ä¸ªæ–‡ä»¶åœ¨ä½ å¯¹åº”çš„ç›®å½•ä¸‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¢«æ­£ç¡®å¼•ç”¨
from .stats import MoEStatsRecorder
from .loss import LoadBalancingLoss
from .collector import MoEAuxCollector

class UltraEfficientRouter(nn.Module):
    """
    èåˆç‰ˆé«˜æ•ˆè·¯ç”±å™¨ï¼š
    1. æ¶æ„ï¼šé‡‡ç”¨ YOLO-Master çš„ Depthwise Separable Conv å‡å°‘å‚æ•°é‡ã€‚
    2. ç­–ç•¥ï¼š
       - è®­ç»ƒæ—¶ï¼šæ³¨å…¥å™ªå£° + Softmaxæƒé‡ + è®¡ç®—è´Ÿè½½å‡è¡¡Loss + ç»Ÿè®¡ä¸“å®¶ä½¿ç”¨ç‡ã€‚
       - æ¨ç†æ—¶ï¼šæ— å™ªå£° + æƒé‡ç½®1 (Hard Routing) + è·³è¿‡Lossè®¡ç®— -> æè‡´é€Ÿåº¦ã€‚
    """
    def __init__(self, in_channels, num_experts, top_k=1, reduction=16, loss_weight=0.5, Layer_id='MoE_Router'):
        super().__init__()
        self.top_k = top_k
        self.num_experts = num_experts
        self.Layer_id = Layer_id

        # --- 1. é«˜æ•ˆè·¯ç”±æ ¸å¿ƒç½‘ç»œ (YOLO-Master é£æ ¼) ---
        # æ¿€è¿›çš„é€šé“å‹ç¼©ï¼Œä½†è‡³å°‘ä¿ç•™ 4 ä¸ªé€šé“
        reduced_channels = max(in_channels // reduction, 4)

        self.router = nn.Sequential(
            # æ·±åº¦å·ç§¯ (DW-Conv): è·å–ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œå¤§å¹…å‡å°‘ FLOPs
            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, groups=in_channels, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.SiLU(inplace=True),

            # é€ç‚¹å·ç§¯ (PW-Conv): é™ç»´
            nn.Conv2d(in_channels, reduced_channels, kernel_size=1, bias=False),
            nn.SiLU(inplace=True),

            # å…¨å±€æ± åŒ– (GAP): å˜æˆå‘é‡ [B, C_red, 1, 1]
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),

            # æœ€ç»ˆåˆ†ç±»å™¨: [B, Num_Experts]
            nn.Linear(reduced_channels, num_experts)
        )

        # --- 2. è¾…åŠ©ç»„ä»¶ (æ¥è‡ªä½ çš„ä»£ç ) ---
        # è´Ÿè½½å‡è¡¡æŸå¤± (å»ºè®®æƒé‡è®¾ä¸º 2.0 æˆ–æ›´é«˜ï¼Œé˜²æ­¢åç¼©)
        self.balance_loss_fn = LoadBalancingLoss(num_experts, loss_weight)

        # ç›‘æµ‹æ•°æ® Buffer (ä¸ä¿å­˜åˆ° state_dictï¼Œç”¨äºè®­ç»ƒç›‘æ§)
        self.register_buffer("selection_states", torch.zeros(num_experts), persistent=False)
        self.register_buffer("expert_scores_sum", torch.zeros(num_experts), persistent=False)
        self.register_buffer("states_step_count", torch.zeros(1), persistent=False)

    def forward(self, x):
        # x: [B, C, H, W]
        # è®¡ç®—åŸå§‹ Logits: [B, Num_Experts]
        logits = self.router(x)
        # print(f"ğŸ‘‰ [Debug 1] logits åˆå§‹ç‰ˆæœ¬: {logits._version}")

        # ================== è®­ç»ƒé˜¶æ®µ (Training) ==================
        if self.training and torch.is_grad_enabled():
            safe_logits = logits
            # 1. æ³¨å…¥å™ªå£° (å…³é”®ï¼šæ‰“ç ´å¯¹ç§°æ€§ï¼Œé˜²æ­¢æ­»ä¸“å®¶)
            # ä½¿ç”¨ 2.0 çš„å™ªå£°å¼ºåº¦ï¼ˆå‚è€ƒä½ çš„ä»£ç ï¼‰
            # noise = torch.randn_like(safe_logits) * 0.1
            noisy_logits = safe_logits
            # print(f"ğŸ‘‰ [Debug 2] åŠ å™ªå£°å logits ç‰ˆæœ¬: {logits._version}")

            # 2. é€‰ Top-K
            # topk_vals: [B, K], topk_indices: [B, K]
            topk_vals, topk_indices = torch.topk(noisy_logits, self.top_k, dim=1)

            # 3. æ•°æ®ç›‘æµ‹ (No Grad)
            with torch.no_grad():
                flat_indices = topk_indices.flatten()
                # ç»Ÿè®¡æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„æ¬¡æ•°
                counts = torch.bincount(flat_indices, minlength=self.num_experts)
                self.selection_states += counts
                # ç»Ÿè®¡åŸå§‹åˆ†æ•°çš„å‡å€¼
                self.expert_scores_sum += logits.mean(dim=0)
                self.states_step_count += 1

            # 4. è½¯è·¯ç”± (Soft Routing) - ä¿ç•™æ¢¯åº¦
            # æ³¨æ„ï¼šè¦ç”¨åŸå§‹ logits (æ— å™ªå£°) çš„å¯¹åº”ä½ç½®æ¥è®¡ç®— Softmaxï¼Œä»¥ä¾¿æ¢¯åº¦å›ä¼ ç»™ Router
            # raw_topk_logits = torch.gather(logits, 1, topk_indices)
            # selected_weights = F.softmax(raw_topk_logits, dim=1)

            global_probs = F.softmax(logits, dim=1) # å¯¹ 4 ä¸ªä¸“å®¶ç®— Softmax
            selected_weights = torch.gather(global_probs, 1, topk_indices)

            # 5. è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±å¹¶æ”¶é›†
            aux_loss = self.balance_loss_fn(logits, topk_indices)
            MoEAuxCollector.add(aux_loss)

            # print(f"ğŸ‘‰ [Debug 3] è¿”å›å‰ logits ç‰ˆæœ¬: {logits._version}, safe_logits ç‰ˆæœ¬: {safe_logits._version}")

            return selected_weights, topk_indices, logits

        # ================== æ¨ç†é˜¶æ®µ (Inference) ==================
        else:
            # 1. ç›´æ¥é€‰ Top-K (æ— å™ªå£°)
            _, topk_indices = torch.topk(logits, self.top_k, dim=1)

            # 2. ç¡¬è·¯ç”± (Hard Routing) - æè‡´æé€Ÿ
            # æ¨ç†æ—¶ä¸éœ€è¦ Softmax çš„è®¡ç®—å¼€é”€ï¼Œä¹Ÿä¸éœ€è¦åŠ æƒæ··åˆ
            # ç›´æ¥æŠŠæƒé‡ç½®ä¸º 1.0ï¼Œå®Œå…¨ä¾èµ–ä¸“å®¶çš„è¾“å‡º
            # å½¢çŠ¶è¦åŒ¹é… [B, TopK]
            selected_weights = torch.ones_like(topk_indices, dtype=logits.dtype, device=logits.device)

            # æ¨ç†æ—¶ä¸è®¡ç®— Aux Loss

            return selected_weights, topk_indices, logits