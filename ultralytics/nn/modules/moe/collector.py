import torch

class MoEAuxCollector:
    _aux = []

    @classmethod
    def add(cls, aux):
        if aux is not None:
            # ç›´æ¥å­˜å…¥ Tensorï¼Œä¿æŒæ¢¯åº¦è¿é€š
            cls._aux.append(aux)

    @classmethod
    def pop_sum(cls, device=None, num_moe_layers=4):
        """
        å¼¹å‡ºå¹¶æ±‚å’Œã€‚
        å¢åŠ  num_moe_layers å‚æ•°ï¼Œé»˜è®¤ 4 ä¸ª MoE å±‚ã€‚
        """
        if not cls._aux:
            return None

        # ğŸ’¥ æ ¸å¿ƒä¿®å¤ï¼šåªå–å½“å‰æœ€æ–°å‰å‘ä¼ æ’­ç”Ÿæˆçš„æœ€å 4 ä¸ª lossï¼
        # å®Œç¾æ‰”æ‰ YOLO åˆå§‹åŒ–æ—¶ç•™ä¸‹çš„ "æ­»èŠ‚ç‚¹(Dummy Loss)"
        valid_aux = cls._aux[-num_moe_layers:]

        if device is not None:
            processed_tensors = [a.to(device) for a in valid_aux]
        else:
            processed_tensors = valid_aux

        # æ±‚å’Œ
        total_aux = torch.stack(processed_tensors).sum()

        # æ¸…ç©ºåˆ—è¡¨ï¼Œè¿æ¥ä¸‹ä¸€ä¸ª Batch
        cls._aux = []

        return total_aux